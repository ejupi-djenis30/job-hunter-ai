<div align="center">
  <h1>ğŸ¯ Job Hunter AI</h1>
  <p><strong>AI-powered Swiss job search platform</strong></p>
  <p>Automated scraping Â· LLM-driven analysis Â· Smart scheduling</p>

  <br/>
  
  ![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)
  ![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)
  ![React](https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=black)
  ![SQLite](https://img.shields.io/badge/SQLite-003B57?logo=sqlite&logoColor=white)
  ![License](https://img.shields.io/badge/License-MIT-yellow)
</div>

---

## Overview

Job Hunter AI is a full-stack application that automates the Swiss job search process. It scrapes listings from [job-room.ch](https://www.job-room.ch) (Switzerland's federal job portal), analyzes them with LLMs to compute affinity scores, and schedules recurring searches â€” so you spend less time browsing and more time applying.

### Key Features

- **ğŸ” Intelligent Scraping** â€” Custom-built scraper engine with CSRF bypass, browser fingerprint simulation, and stealth mode
- **ğŸ¤– LLM-Powered Analysis** â€” Upload your CV and get AI-generated affinity scores and fit analysis for each job
- **â° Scheduled Searches** â€” Set up recurring search profiles that run automatically on your schedule
- **ğŸ“Š Dashboard** â€” React-based UI to manage searches, review results, and track applications
- **ğŸ” Authentication** â€” JWT-based auth with PBKDF2-SHA256 password hashing

---

## Architecture

```
job-hunter-ai/
â”œâ”€â”€ backend/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py                 # API routes & app lifecycle
â”‚   â”œâ”€â”€ models.py               # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ schemas.py              # Pydantic request/response schemas
â”‚   â”œâ”€â”€ database.py             # Database configuration
â”‚   â”œâ”€â”€ services/               # Business logic layer
â”‚   â”‚   â”œâ”€â”€ auth.py             # JWT + password hashing
â”‚   â”‚   â”œâ”€â”€ llm.py              # LLM integration (OpenAI-compatible)
â”‚   â”‚   â”œâ”€â”€ scraper.py          # Search orchestration
â”‚   â”‚   â”œâ”€â”€ reference.py        # CV/profile management
â”‚   â”‚   â”œâ”€â”€ scheduler.py        # APScheduler background jobs
â”‚   â”‚   â””â”€â”€ search_status.py    # Real-time search progress tracking
â”‚   â””â”€â”€ scraper/                # Embedded scraper engine
â”‚       â”œâ”€â”€ core/               # Models, session mgmt, exceptions
â”‚       â””â”€â”€ providers/          # Job portal implementations
â”‚           â””â”€â”€ job_room/       # job-room.ch provider
â”œâ”€â”€ frontend/                   # React + Vite application
â”œâ”€â”€ tests/                      # Comprehensive test suite
â”‚   â”œâ”€â”€ unit/                   # Model, auth, scraper tests
â”‚   â”œâ”€â”€ integration/            # API endpoint tests
â”‚   â””â”€â”€ e2e/                    # Live scraper tests
â”œâ”€â”€ pyproject.toml              # Python project configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ .env.example                # Environment variable template
```

### Scraper Engine

The embedded scraper engine (originally a standalone library) provides:

| Feature | Description |
|---------|-------------|
| **Anti-Detection** | HTTP/2, browser fingerprinting, realistic headers |
| **CSRF Handling** | Automatic Angular XSRF token management |
| **Execution Modes** | FAST (speed) Â· STEALTH (evasion) Â· AGGRESSIVE (retry) |
| **BFS Mapper** | Swiss municipality â†’ BFS code resolution (150+ cities) |
| **Provider Pattern** | Extensible `BaseJobProvider` for adding new sources |

---

## Getting Started

### Prerequisites

- **Python 3.11+**
- **Node.js 18+** (for the frontend)

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/JobGipfel/job-hunter-ai.git
cd job-hunter-ai

# Create and activate virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys and settings

# Start the backend
python run.py
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

The frontend will be available at `http://localhost:5173` and the API at `http://localhost:8000`.

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `JWT_SECRET_KEY` | Secret for signing JWT tokens | âœ… |
| `LLM_PROVIDER` | LLM backend (`groq` or `deepseek`) | âœ… |
| `LLM_API_KEY` | API key for the LLM provider | âœ… |
| `DATABASE_URL` | SQLAlchemy database URL | Optional |
| `API_PORT` | Backend port (default: 8000) | Optional |

See [`.env.example`](.env.example) for the full list.

---

## Testing

```bash
# Run all tests (excluding live tests)
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ --cov=backend --cov-report=term-missing

# Run live tests (hits real APIs)
python -m pytest tests/ --run-live -v
```

**Test Coverage:**

- ğŸ“¦ **Scraper Models** â€” Request validation, listing creation, response pagination
- ğŸ—ºï¸ **BFS Mapper** â€” City/postal code resolution, partial matching, error handling
- ğŸ” **Authentication** â€” Password hashing, JWT creation/verification
- ğŸ—„ï¸ **Database** â€” ORM model creation, constraints, defaults
- ğŸ“¡ **API Integration** â€” Auth flow, protected endpoints, CRUD operations
- ğŸŒ **E2E Live** â€” Real scraper searches against job-room.ch (gated)

---

## How It Works

1. **Create a Profile** â€” Define your search criteria (role, location, workload, CV)
2. **Generate Keywords** â€” The LLM analyzes your profile to create optimized search queries
3. **Scrape Jobs** â€” The engine searches job-room.ch with each generated query
4. **Analyze Results** â€” Each job is scored by the LLM for relevance to your profile
5. **Review & Apply** â€” Browse ranked results in the dashboard and track applications

---

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Backend** | FastAPI, SQLAlchemy, APScheduler |
| **Frontend** | React 18, Vite, Bootstrap |
| **Scraping** | httpx (HTTP/2), tenacity |
| **AI/LLM** | OpenAI-compatible (Groq, DeepSeek) |
| **Database** | SQLite |
| **Auth** | JWT (PyJWT), PBKDF2-SHA256 |
| **Testing** | pytest, pytest-asyncio |

---

## License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
