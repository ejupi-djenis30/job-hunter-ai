<div align="center">
  <h1>ğŸ¯ Job Hunter AI</h1>
  <p><strong>AI-powered Swiss job search platform</strong></p>
  <p>Automated scraping Â· LLM-driven analysis Â· Smart scheduling</p>

  <br/>
  
  ![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)
  ![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)
  ![React](https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=black)
  ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-4169E1?logo=postgresql&logoColor=white)
  ![SQLite](https://img.shields.io/badge/SQLite-003B57?logo=sqlite&logoColor=white)
  ![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
  ![License](https://img.shields.io/badge/License-MIT-yellow)
</div>

---

## Overview

Job Hunter AI is a full-stack application that automates the Swiss job search process. It scrapes listings from [job-room.ch](https://www.job-room.ch) (Switzerland's federal job portal), analyzes them with LLMs to compute affinity scores, and schedules recurring searches â€” so you spend less time browsing and more time applying.

### Key Features

- **ğŸ” Intelligent Scraping** â€” Custom-built scraper engine with CSRF bypass, browser fingerprint simulation, and stealth mode
- **ğŸ¤– LLM-Powered Analysis** â€” Upload your CV and get AI-generated affinity scores and fit analysis for each job
- **â° Scheduled Searches** â€” Set up recurring search profiles that run automatically on your schedule
- **ğŸ“Š Dashboard** â€” React-based UI to manage searches, review results, and track applications
- **ğŸ” Authentication** â€” JWT-based auth with PBKDF2-SHA256 password hashing
- **ğŸ˜ Dual Database** â€” SQLite for local dev, PostgreSQL for production â€” auto-detected from `DATABASE_URL`
- **ğŸ³ Docker Ready** â€” Optional `docker-compose` deployment with PostgreSQL

---

## Architecture

```
job-hunter-ai/
â”œâ”€â”€ backend/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py                 # App setup, middleware, router includes
â”‚   â”œâ”€â”€ models.py               # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ schemas.py              # Pydantic v2 request/response schemas
â”‚   â”œâ”€â”€ database.py             # DB config (SQLite / PostgreSQL auto-detect)
â”‚   â”œâ”€â”€ routes/                 # API route modules
â”‚   â”‚   â”œâ”€â”€ auth.py             # /auth â€” register, login
â”‚   â”‚   â”œâ”€â”€ jobs.py             # /jobs â€” CRUD operations
â”‚   â”‚   â”œâ”€â”€ search.py           # Search workflow, CV upload, status
â”‚   â”‚   â””â”€â”€ profiles.py        # Profile management, scheduling
â”‚   â”œâ”€â”€ services/               # Business logic layer
â”‚   â”‚   â”œâ”€â”€ auth.py             # JWT + password hashing
â”‚   â”‚   â”œâ”€â”€ llm.py              # LLM integration (OpenAI-compatible)
â”‚   â”‚   â”œâ”€â”€ scraper.py          # Search orchestration
â”‚   â”‚   â”œâ”€â”€ reference.py        # Occupation code resolution
â”‚   â”‚   â”œâ”€â”€ scheduler.py        # APScheduler background jobs
â”‚   â”‚   â”œâ”€â”€ search_status.py    # Real-time search progress tracking
â”‚   â”‚   â””â”€â”€ utils.py            # File processing (PDF, TXT)
â”‚   â””â”€â”€ scraper/                # Embedded scraper engine
â”‚       â”œâ”€â”€ core/               # Models, session mgmt, exceptions
â”‚       â””â”€â”€ providers/          # Job portal implementations
â”‚           â””â”€â”€ job_room/       # job-room.ch provider
â”œâ”€â”€ frontend/                   # React + Vite application
â”œâ”€â”€ alembic/                    # Database migrations
â”œâ”€â”€ tests/                      # Comprehensive test suite (63 tests)
â”‚   â”œâ”€â”€ unit/                   # Model, auth, scraper tests
â”‚   â”œâ”€â”€ integration/            # API endpoint tests
â”‚   â””â”€â”€ e2e/                    # Live scraper tests
â”œâ”€â”€ Dockerfile                  # Multi-stage production build
â”œâ”€â”€ docker-compose.yml          # App + PostgreSQL deployment
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ .env.example                # Environment variable template
```

### Scraper Engine

The embedded scraper engine (originally a standalone library) provides:

| Feature | Description |
|---------|-------------|
| **Anti-Detection** | HTTP/2, browser fingerprinting, realistic headers |
| **CSRF Handling** | Automatic Angular XSRF token management |
| **Execution Modes** | FAST (speed) Â· STEALTH (evasion) Â· AGGRESSIVE (retry) |
| **BFS Mapper** | Swiss municipality â†’ BFS code resolution (150+ cities) |
| **Provider Pattern** | Extensible `BaseJobProvider` for adding new sources |

---

## Getting Started

### Option 1: Local Development

#### Prerequisites

- **Python 3.11+**
- **Node.js 18+** (for the frontend)

```bash
# Clone the repository
git clone https://github.com/JobGipfel/job-hunter-ai.git
cd job-hunter-ai

# Create and activate virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys and settings

# Start the backend
python run.py
```

```bash
# Frontend (separate terminal)
cd frontend
npm install
npm run dev
```

The frontend will be available at `http://localhost:5173` and the API at `http://localhost:8000`.

### Option 2: Docker Deployment

```bash
# Clone and configure
git clone https://github.com/JobGipfel/job-hunter-ai.git
cd job-hunter-ai
cp .env.example .env
# Edit .env with your API keys

# Start with PostgreSQL
docker-compose up -d

# Or start app only (SQLite mode)
docker-compose up -d app
```

### Database Migrations (Alembic)

```bash
# Generate a new migration after model changes
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head
```

---

## Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `JWT_SECRET_KEY` | Secret for signing JWT tokens | âœ… |
| `LLM_PROVIDER` | LLM backend (`groq` or `deepseek`) | âœ… |
| `GROQ_API_KEY` / `DEEPSEEK_API_KEY` | API key for the chosen provider | âœ… |
| `DATABASE_URL` | `sqlite:///./job_hunter.db` or `postgresql://...` | Optional |
| `CORS_ORIGINS` | Comma-separated allowed origins | Optional |
| `API_HOST` / `API_PORT` | Server bind address (default: `127.0.0.1:8000`) | Optional |
| `LOG_LEVEL` | Logging level (default: `INFO`) | Optional |

See [`.env.example`](.env.example) for the full list with LLM configuration options.

---

## Testing

```bash
# Run all tests (excluding live tests)
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ --cov=backend --cov-report=term-missing

# Run live tests (hits real APIs)
python -m pytest tests/ --run-live -v
```

**Test Coverage (63 tests):**

- ğŸ“¦ **Scraper Models** â€” Request validation, listing creation, response pagination
- ğŸ—ºï¸ **BFS Mapper** â€” City/postal code resolution, partial matching, error handling
- ğŸ” **Authentication** â€” Password hashing, JWT creation/verification
- ğŸ—„ï¸ **Database** â€” ORM model creation, constraints, defaults
- ğŸ“¡ **API Integration** â€” Auth flow, protected endpoints, CRUD operations
- ğŸŒ **E2E Live** â€” Real scraper searches against job-room.ch (gated by `--run-live`)

---

## How It Works

1. **Create a Profile** â€” Define your search criteria (role, location, workload, CV)
2. **Generate Keywords** â€” The LLM analyzes your profile to create optimized, multilingual search queries
3. **Scrape Jobs** â€” The engine searches job-room.ch with each generated query
4. **Analyze Results** â€” Each job is scored by the LLM for relevance to your profile
5. **Review & Apply** â€” Browse ranked results in the dashboard and track applications

---

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Backend** | FastAPI, SQLAlchemy, Alembic, APScheduler |
| **Frontend** | React 18, Vite, Bootstrap |
| **Scraping** | httpx (HTTP/2), tenacity |
| **AI/LLM** | OpenAI-compatible (Groq, DeepSeek) |
| **Database** | SQLite (dev) / PostgreSQL (production) |
| **Auth** | JWT (PyJWT), PBKDF2-SHA256 |
| **Deploy** | Docker, gunicorn + uvicorn |
| **Testing** | pytest, pytest-asyncio |

---

## License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
