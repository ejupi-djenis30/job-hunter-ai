# ═══════════════════════════════════════════════════════════════════════════════
# Job Hunter AI — Environment Configuration
# ═══════════════════════════════════════════════════════════════════════════════
# Copy this file to .env and fill in your values:  cp .env.example .env

# ─── Application ──────────────────────────────────────────────────────────────
PROJECT_NAME=Job Hunter AI
API_V1_STR=/api/v1
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173,http://localhost:8000

# ─── Security ─────────────────────────────────────────────────────────────────
SECRET_KEY=CHANGE_ME_TO_A_RANDOM_SECURE_STRING
ACCESS_TOKEN_EXPIRE_MINUTES=11520

# ─── Database ─────────────────────────────────────────────────────────────────
# Docker (PostgreSQL):
# DATABASE_URL=postgresql://user:password@db:5432/jobhunter
# Local (SQLite):
DATABASE_URL=sqlite:///./job_hunter.db

# ─── Postgres (Docker only) ──────────────────────────────────────────────────
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=jobhunter

# ═══════════════════════════════════════════════════════════════════════════════
# LLM CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════
#
# The LLM layer has two tiers:
#   1. GLOBAL settings  — used by default for every pipeline step
#   2. PER-STEP overrides — optionally override any global setting for a
#      specific step.  Leave empty/zero to inherit the global value.
#
# Pipeline steps:  PLAN  →  RELEVANCE  →  MATCH
#   PLAN       = generate search queries from the user's profile
#   RELEVANCE  = quick yes/no filter on job title relevance
#   MATCH      = deep analysis scoring a job against the user's CV
#
# ═══════════════════════════════════════════════════════════════════════════════

# ─── Global LLM (fallback for all steps) ──────────────────────────────────────
LLM_PROVIDER=groq                              # groq | deepseek | openai | gemini | ollama
LLM_API_KEY=your_api_key_here                  # REQUIRED — your provider's API key
LLM_BASE_URL=https://api.groq.com/openai/v1   # Provider API endpoint
LLM_MODEL=moonshotai/kimi-k2-instruct-0905     # Model name/ID
LLM_TEMPERATURE=0.7                            # Creativity (0.0 = deterministic, 1.0 = creative)
LLM_TOP_P=0.95                                 # Nucleus sampling (0.0–1.0)
LLM_MAX_TOKENS=16384                           # Max output tokens
LLM_THINKING=false                             # Enable thinking/reasoning mode (deepseek)
LLM_THINKING_LEVEL=OFF                         # Gemini thinking level: OFF | LOW | MEDIUM | HIGH

# ─── Ollama defaults (used when LLM_PROVIDER=ollama) ─────────────────────────
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3

# ═══════════════════════════════════════════════════════════════════════════════
# PER-STEP OVERRIDES  (all optional — leave empty to use global values)
# ═══════════════════════════════════════════════════════════════════════════════
#
# Example: use a small cheap model for the binary relevance check,
# and a powerful model for the deep match analysis:
#
#   LLM_RELEVANCE_MODEL=llama-3.1-8b-instant
#   LLM_RELEVANCE_TEMPERATURE=0.1
#   LLM_RELEVANCE_MAX_TOKENS=1024
#
#   LLM_MATCH_PROVIDER=deepseek
#   LLM_MATCH_MODEL=deepseek-chat
#   LLM_MATCH_API_KEY=sk-...
#   LLM_MATCH_BASE_URL=https://api.deepseek.com
#   LLM_MATCH_TEMPERATURE=0.3
#   LLM_MATCH_THINKING=true

# ─── Step: PLAN (search query generation) ────────────────────────────────────
# LLM_PLAN_PROVIDER=
# LLM_PLAN_MODEL=
# LLM_PLAN_API_KEY=
# LLM_PLAN_BASE_URL=
# LLM_PLAN_TEMPERATURE=
# LLM_PLAN_TOP_P=
# LLM_PLAN_MAX_TOKENS=
# LLM_PLAN_THINKING=
# LLM_PLAN_THINKING_LEVEL=

# ─── Step: RELEVANCE (title relevance check) ─────────────────────────────────
# LLM_RELEVANCE_PROVIDER=
# LLM_RELEVANCE_MODEL=
# LLM_RELEVANCE_API_KEY=
# LLM_RELEVANCE_BASE_URL=
# LLM_RELEVANCE_TEMPERATURE=
# LLM_RELEVANCE_TOP_P=
# LLM_RELEVANCE_MAX_TOKENS=
# LLM_RELEVANCE_THINKING=
# LLM_RELEVANCE_THINKING_LEVEL=

# ─── Step: MATCH (job match analysis) ────────────────────────────────────────
# LLM_MATCH_PROVIDER=
# LLM_MATCH_MODEL=
# LLM_MATCH_API_KEY=
# LLM_MATCH_BASE_URL=
# LLM_MATCH_TEMPERATURE=
# LLM_MATCH_TOP_P=
# LLM_MATCH_MAX_TOKENS=
# LLM_MATCH_THINKING=
# LLM_MATCH_THINKING_LEVEL=

# ─── Scraping ─────────────────────────────────────────────────────────────────
# JOB_ROOM_USER_AGENT=Mozilla/5.0 ...
